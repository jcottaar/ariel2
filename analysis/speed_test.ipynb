{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f83b89e4-ae65-4669-9e78-15f817bc2b71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/mnt/d/ariel2/code/core/')\n",
    "sys.path.append('d:/ariel2/code/core/')\n",
    "sys.path.append('/kaggle/input/my-ariel2-library')\n",
    "import kaggle_support as kgs\n",
    "import ariel_model\n",
    "import ariel_gp\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99b7ffc2-2f42-4ba8-a481-813c55251753",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = kgs.load_all_train_data()\n",
    "test_data = kgs.load_all_test_data()\n",
    "kgs.debugging_mode = 1\n",
    "model = ariel_gp.PredictionModel()\n",
    "model.run_in_parallel = True\n",
    "kgs.sanity_checks_active=True\n",
    "model.train(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab06445-2bfd-4b18-9d1d-57e6e1bd0cc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in parallel:   0%|                                                                    | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local\n",
      "SpawnPoolWorker-2 2\n",
      "CUDA_VISIBLE_DEVICES= 0\n",
      "local\n",
      "local\n",
      "SpawnPoolWorker-3 3\n",
      "SpawnPoolWorker-1 1\n",
      "CUDA_VISIBLE_DEVICES= 0CUDA_VISIBLE_DEVICES=\n",
      " 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in parallel: 100%|███████████████████████████████████████████████████████████| 12/12 [01:32<00:00,  7.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in parallel:   0%|                                                                    | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local\n",
      "SpawnPoolWorker-4 4\n",
      "CUDA_VISIBLE_DEVICES= 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in parallel: 100%|███████████████████████████████████████████████████████████| 12/12 [04:20<00:00, 21.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[260.34995914   0.           0.        ]\n",
      " [  0.           0.           0.        ]\n",
      " [  0.           0.           0.        ]\n",
      " [  0.           0.           0.        ]]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in parallel:   0%|                                                                    | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local\n",
      "SpawnPoolWorker-5 5\n",
      "CUDA_VISIBLE_DEVICES= 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in parallel: 100%|███████████████████████████████████████████████████████████| 12/12 [04:00<00:00, 20.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[260.34995914 240.9146626    0.        ]\n",
      " [  0.           0.           0.        ]\n",
      " [  0.           0.           0.        ]\n",
      " [  0.           0.           0.        ]]\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing in parallel:   0%|                                                                    | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local\n",
      "SpawnPoolWorker-6 6\n",
      "CUDA_VISIBLE_DEVICES= 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in parallel: 100%|███████████████████████████████████████████████████████████| 12/12 [03:55<00:00, 19.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[260.34995914 240.9146626  233.01151872]\n",
      " [  0.           0.           0.        ]\n",
      " [  0.           0.           0.        ]\n",
      " [  0.           0.           0.        ]]\n",
      "inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in parallel:   0%|                                                                    | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local\n",
      "local\n",
      "SpawnPoolWorker-8 8\n",
      "CUDA_VISIBLE_DEVICES= 0\n",
      "SpawnPoolWorker-7 7\n",
      "CUDA_VISIBLE_DEVICES= 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in parallel:  33%|████████████████████                                        | 4/12 [01:31<02:58, 22.35s/it]"
     ]
    }
   ],
   "source": [
    "n_workers_list = [1,2,3,4]\n",
    "n_threads_list = [np.inf,1,2]\n",
    "N=12\n",
    "\n",
    "res = np.zeros((len(n_workers_list), len(n_threads_list)))\n",
    "# Warmup\n",
    "print(N)\n",
    "#kgs.n_workers = 2\n",
    "#kgs.n_threads = 1\n",
    "print(len(train_data[:N]))\n",
    "model.infer(train_data[:N])\n",
    "for i in range(len(n_workers_list)):\n",
    "    for j in range(len(n_threads_list)):\n",
    "        kgs.n_workers = n_workers_list[i]\n",
    "        kgs.n_threads = n_threads_list[j]\n",
    "        print(kgs.n_threads)\n",
    "        tt=time.time()\n",
    "        model.run_in_parallel = (kgs.n_workers>0)\n",
    "        if kgs.n_workers<=2 or kgs.n_threads<=2:\n",
    "            model.infer(train_data[:N])\n",
    "        res[i,j] = time.time()-tt\n",
    "        print(res)\n",
    "\n",
    "# Improve this part        \n",
    "print(res)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame for nice formatting\n",
    "df = pd.DataFrame(\n",
    "    res,\n",
    "    index=[f\"{w} workers\" for w in n_workers_list],\n",
    "    columns=[f\"{t} threads\" for t in n_threads_list]\n",
    ")\n",
    "\n",
    "# Print as a table with 3 decimal places\n",
    "print(df.round(3).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b0b9c1-a550-40b1-9fd2-f44d9ba0b319",
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95753661-c746-46ae-8fc0-93bf4f6abb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.bias_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b8c34f-029e-486e-aa64-6846cd9c5fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
