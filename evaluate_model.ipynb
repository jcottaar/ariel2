{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b8a753e-265c-405a-afed-c28686cd8cc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e798b120-18d1-4041-b7d9-d3d0c23289a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/mnt/d/ariel2/code/core/')\n",
    "sys.path.append('d:/ariel2/code/core/')\n",
    "sys.path.append('/kaggle/input/my-ariel2-library')\n",
    "import kaggle_support as kgs\n",
    "import ariel_model\n",
    "import ariel_simple\n",
    "import ariel_gp\n",
    "import ariel_load\n",
    "import ariel_load_FGS\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import importlib\n",
    "from tqdm import tqdm\n",
    "kgs.debugging_mode = 1\n",
    "kgs.profiling=False\n",
    "kgs.n_workers = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d51b008-8696-47a9-ace8-2dc939e9753d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = kgs.load_all_train_data()\n",
    "train_data = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88e2a4e1-6391-47b0-a83f-e2ad86270387",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# importlib.reload(kgs)\n",
    "# for d in train_data:\n",
    "#     d.spectrum_cov = np.ones((283,283))\n",
    "# kgs.mats_to_data(train_data, train_data, kgs.data_to_mats(train_data,train_data))\n",
    "# kgs.score_metric(train_data, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5491c23b-ddd5-41de-8348-be026a573a00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "importlib.reload(ariel_model)\n",
    "todo = dict()\n",
    "\n",
    "# model = ariel_model.baseline_model()\n",
    "# model.model.run_in_parallel = True\n",
    "# todo['New transit prior, alpha=1.0, FGSs=0.0001'] = model\n",
    "\n",
    "model = ariel_model.baseline_model()\n",
    "model.model.run_in_parallel = True\n",
    "todo['Baseline'] = model\n",
    "\n",
    "model = ariel_model.baseline_model()\n",
    "model.model.run_in_parallel = True\n",
    "model = ariel_model.Fudger3(model=model.model)\n",
    "todo['Fudger3'] = model\n",
    "\n",
    "# model = ariel_model.baseline_model()\n",
    "# model.model.run_in_parallel = True\n",
    "# model.model.model_options.AIRS_noise_scaling = 1e4\n",
    "# todo['Baseline FGS only'] = model\n",
    "\n",
    "# model = ariel_model.baseline_model()\n",
    "# model.model.run_in_parallel = True\n",
    "# model.model.model_options.AIRS_noise_scaling = 1e4\n",
    "# model.model.model_options.FGS_noise_scaling = 1.6\n",
    "# todo['Baseline FGS only, exaggerate FGS noise'] = model\n",
    "\n",
    "# model = ariel_model.baseline_model()\n",
    "# model.model.run_in_parallel = True\n",
    "# model.model.model_options.AIRS_noise_scaling = 1e4\n",
    "# loaders = model.model.starter_model.loaders\n",
    "# loaders[0].apply_full_sensor_corrections.restore_invalids = False\n",
    "# loaders[0].apply_wavelength_binning = ariel_load.ApplyWavelengthBinning()\n",
    "# loaders[1].apply_wavelength_binning = ariel_load.ApplyWavelengthBinning()\n",
    "# loaders[1].apply_full_sensor_corrections.inpainting_wavelength = True\n",
    "# loaders[1].apply_full_sensor_corrections.use_pca_for_background_removal = False\n",
    "# loaders[1].apply_full_sensor_corrections.remove_background_based_on_rows = True\n",
    "# loaders[1].apply_full_sensor_corrections.remove_background_remove_used_rows = True\n",
    "# todo['Baseline FGS only, simplified loader'] = model\n",
    "\n",
    "# model = ariel_model.baseline_model()\n",
    "# model.model.run_in_parallel = True\n",
    "# model.model.model_options.AIRS_noise_scaling = 1e4\n",
    "# model.model.model_options.FGS_order = 1\n",
    "# todo['Baseline FGS only, drift order 1'] = model\n",
    "\n",
    "# model = ariel_model.baseline_model()\n",
    "# model.model.run_in_parallel = True\n",
    "# model.model.model_options.AIRS_noise_scaling = 1e4\n",
    "# model.model.model_options.FGS_order = 2\n",
    "# todo['Baseline FGS only, drift order 2'] = model\n",
    "\n",
    "# model = ariel_model.baseline_model()\n",
    "# model.model.run_in_parallel = True\n",
    "# model.model.model_options.AIRS_noise_scaling = 1e4\n",
    "# model.model.model_options.FGS_order = 5\n",
    "# todo['Baseline FGS only, drift order 5'] = model\n",
    "\n",
    "# model = ariel_model.baseline_model()\n",
    "# model.model.run_in_parallel = True\n",
    "# model.model.model_options.AIRS_noise_scaling = 1e4\n",
    "# model.model.model_options.FGS_transit_override = ('linear', 1)\n",
    "# todo['Baseline FGS only, linear limb darkening'] = model\n",
    "\n",
    "# model = ariel_model.baseline_model()\n",
    "# model.model.run_in_parallel = True\n",
    "# model.model.model_options.AIRS_noise_scaling = 1e4\n",
    "# model.model.model_options.FGS_transit_override = ('nonuniform', 4)\n",
    "# todo['Baseline FGS only, nonuniform limb darkening'] = model\n",
    "\n",
    "\n",
    "# model = ariel_model.baseline_model()\n",
    "# model.model.run_in_parallel = True\n",
    "# todo['Baseline'] = model\n",
    "\n",
    "# for alpha in [1.]:\n",
    "#     for sigma_override in [1e-4]:\n",
    "#         model = ariel_model.baseline_model()\n",
    "#         model.model.run_in_parallel = True\n",
    "#         model.model.model_options.use_old_transit_depth_prior = False\n",
    "#         model.model.model_options.new_transit_depth_FGS_sigma_override = sigma_override\n",
    "#         model.model.model_options.transit_depth_alpha = alpha\n",
    "#         todo[f'New transit prior, alpha={alpha}, FGSs={sigma_override}'] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95753661-c746-46ae-8fc0-93bf4f6abb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 1099/1099 [00:16<00:00, 68.06it/s]\n",
      "Processing in parallel:   0%|                                                                  | 0/1099 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local\n",
      "local\n",
      "local\n",
      "local\n",
      "local\n",
      "SpawnPoolWorker-2 2\n",
      "SpawnPoolWorker-1 1\n",
      "CUDA_VISIBLE_DEVICES= 0\n",
      "SpawnPoolWorker-4 4\n",
      "CUDA_VISIBLE_DEVICES= 0\n",
      "CUDA_VISIBLE_DEVICES= 0\n",
      "SpawnPoolWorker-3 3\n",
      "CUDA_VISIBLE_DEVICES= 0\n",
      "SpawnPoolWorker-6 6\n",
      "CUDA_VISIBLE_DEVICES= 0\n",
      "local\n",
      "SpawnPoolWorker-5 5\n",
      "CUDA_VISIBLE_DEVICES= 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in parallel:   3%|█▊                                                       | 36/1099 [01:14<30:33,  1.73s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "kgs.sanity_checks_active = True\n",
    "def fname(k):\n",
    "    return kgs.temp_dir + 'evaluate_model_'+k+'__'+str(len(train_data))+'.pickle'\n",
    "for k,v in todo.items():\n",
    "    if not os.path.isfile(fname(k)):\n",
    "        print(k)\n",
    "        model = copy.deepcopy(v)\n",
    "        \n",
    "#         print('!!! also loader')\n",
    "        if k=='Fudger3':\n",
    "            \n",
    "            model_ref = kgs.dill_load(fname('New transit prior, alpha=1.0, FGSs=0.0001'))[1]\n",
    "            model._cached_planet_id = model_ref._cached_planet_id\n",
    "            model._cached_result = model_ref._cached_result\n",
    "            model.bias_a = model_ref.bias_a\n",
    "            model.bias_b = model_ref.bias_b\n",
    "            model.sigma_fudge_FGS = model_ref.sigma_fudge[0]\n",
    "            model.sigma_fudge_AIRS_mean = model_ref.sigma_fudge[1]\n",
    "            model.sigma_fudge_AIRS_var = model_ref.sigma_fudge[1]\n",
    "        \n",
    "        # Precache data\n",
    "        for d in tqdm(train_data):\n",
    "            copy.deepcopy(d).load_to_step(5,model.model.starter_model.loaders)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #model.state=1\n",
    "        model.train(train_data)\n",
    "        #kgs.list_attrs(model)\n",
    "        inferred_data = model.infer(train_data)\n",
    "        print(k)\n",
    "        print(kgs.score_metric(inferred_data, train_data))\n",
    "        #print('not saving')\n",
    "        #kgs.list_attrs(model)\n",
    "        kgs.dill_save(fname(k), (inferred_data,model,kgs.git_commit_id))\n",
    "    else:\n",
    "        print(k)\n",
    "        (inferred_data,model,_) = kgs.dill_load(fname(k))\n",
    "        #print(model.model.model_options.FGS_order)\n",
    "        print(kgs.score_metric(inferred_data, train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6925203d-edc7-42b8-87df-304eadb3f5d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fb2548-b86c-47ba-9aa7-ec5ec470c748",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ignore_bad_planets = False\n",
    "def filter_bad_data(data):\n",
    "    data_out = []\n",
    "    for d in data:\n",
    "        if not d.planet_id in [1349926825, 3786449677, 2554492145, 1267010874, 94572221, 2270815333, 3649218579, 576917580, 2154305089, 2207815333, 2740910036]:\n",
    "            data_out.append(d)\n",
    "    return data_out\n",
    "        \n",
    "def basics():\n",
    "    plt.grid(True)\n",
    "    plt.box(True)\n",
    "def plot_two_sensors(func, xl, yl, mod):\n",
    "    _,ax = plt.subplots(1,2,figsize=(12,6))\n",
    "    plt.sca(ax[0]);basics()\n",
    "    plt.title('FGS')\n",
    "    plt.xlabel(xl)\n",
    "    plt.ylabel(yl)\n",
    "    func(slice(0,1), 'blue', 'FGS')\n",
    "    mod()\n",
    "    \n",
    "    plt.sca(ax[1]);basics()\n",
    "    plt.title('AIRS')\n",
    "    plt.xlabel(xl)\n",
    "    func(slice(1,283), 'red', 'AIRS')\n",
    "    mod()\n",
    "    \n",
    "    plt.pause(0.001)\n",
    "\n",
    "def report_extreme_ratios(x,y,name):\n",
    "    \n",
    "    print(name)\n",
    "    inds = np.argsort(np.abs(y/x))[::-1]\n",
    "    for ii in inds[:2]:\n",
    "        print(f'{inferred_data[ii].planet_id}, ratio:{np.abs(y[ii]/x[ii]):.3f}, x:{x[ii]:.3e}, y:{y[ii]:.3e}, RMS:{kgs.rms(error_matrix[ii,:]):.3e}')\n",
    "    \n",
    "    \n",
    "for k,v in todo.items():\n",
    "    (inferred_data,model,_) = kgs.dill_load(fname(k))\n",
    "    if ignore_bad_planets:\n",
    "        inferred_data = filter_bad_data(inferred_data)\n",
    "        train_data_here = filter_bad_data(train_data)\n",
    "    else:\n",
    "        train_data_here = train_data\n",
    "    #model.bias_a[0]+=0.006\n",
    "    #model.bias_a[1]-=0.0002\n",
    "    #inferred_data = model.infer(train_data)\n",
    "    \n",
    "    \n",
    "    print(k)\n",
    "    #print(model.bias_a)\n",
    "    #print(model.bias_b)\n",
    "    #print(model.sigma_offset)\n",
    "    #print(model.sigma_fudge_FGS, model.sigma_fudge_AIRS_mean, model.sigma_fudge_AIRS_var)\n",
    "    print(kgs.score_metric(inferred_data, train_data_here,print_results=True))\n",
    "    print('')\n",
    "    \n",
    "    \n",
    "    #try:\n",
    "    #    print(model.sigma_offset)\n",
    "    #except: pass\n",
    "    #print(model.sigma_fudge)    \n",
    "    #kgs.list_attrs(model)\n",
    "    kgs.score_metric(inferred_data, train_data_here)\n",
    "    print('')\n",
    "    print('20')\n",
    "    kgs.score_metric(inferred_data[:20], train_data_here[:20]) \n",
    "    print('')\n",
    "    #print('No fudge')\n",
    "    #model.sigma_fudge = [1,1]\n",
    "    #try: model.sigma_offset = [0,0]\n",
    "    #except: pass\n",
    "    #model.bias_a = [1,1]\n",
    "    #model.bias_b = [0,0]\n",
    "    # print('!!!')\n",
    "    #inferred_data = model.infer(train_data)\n",
    "    if ignore_bad_planets:\n",
    "        inferred_data = filter_bad_data(inferred_data)\n",
    "    kgs.score_metric(inferred_data, train_data_here)     \n",
    "    error_matrix = np.array([d.spectrum - t.spectrum for d,t in zip(inferred_data,train_data_here)])\n",
    "    true_matrix = np.array([t.spectrum for d,t in zip(inferred_data,train_data_here)])\n",
    "    \n",
    "    def plot_prediction_vs_true(slic, col, name):\n",
    "        x = np.mean(true_matrix[:,slic],1)\n",
    "        y = np.mean(error_matrix[:,slic],1)\n",
    "        plt.scatter(x,y,color = col)\n",
    "        report_extreme_ratios(x,y,name)\n",
    "        \n",
    "    plot_two_sensors(plot_prediction_vs_true, 'True value (mean)', 'Prediction error (mean)', lambda:0)\n",
    "    \n",
    "    def plot_mean_error_vs_sigma(slic,col, name):\n",
    "        x = [np.sqrt(np.sum(d.spectrum_cov[slic,slic])/(slic.stop-slic.start)**2) for d in inferred_data]\n",
    "        y = np.mean(error_matrix[:,slic],1)\n",
    "        plt.scatter(x,y,color = col)\n",
    "        report_extreme_ratios(x,y,name)\n",
    "    def mod():\n",
    "        plt.axline((0,0), slope=3, color='black')\n",
    "        plt.axline((0,0), slope=-3, color = 'black')        \n",
    "    plot_two_sensors(plot_mean_error_vs_sigma, 'Sigma prediction (mean)', 'Prediction error (mean)', mod)\n",
    "    \n",
    "    def plot_mean_error_vs_sigma(slic,col, name):\n",
    "        x = np.mean(true_matrix[:,slic],1)\n",
    "        y = np.mean(error_matrix[:,slic],1) / np.array([np.sqrt(np.sum(d.spectrum_cov[slic,slic])/(slic.stop-slic.start)**2) for d in inferred_data])\n",
    "        plt.scatter(x,y,color = col)\n",
    "        report_extreme_ratios(x,y,name)    \n",
    "    plot_two_sensors(plot_mean_error_vs_sigma, 'True value (mean)', 'Prediction error / sigma (mean)', lambda:0)\n",
    "    \n",
    "    def plot_mean_error_vs_sigma(slic,col, name):\n",
    "        x = np.std(true_matrix[:,1:],1)\n",
    "        y = np.mean(error_matrix[:,slic],1) / np.array([np.sqrt(np.sum(d.spectrum_cov[slic,slic])/(slic.stop-slic.start)**2) for d in inferred_data])\n",
    "        #y = np.mean(error_matrix[:,slic],1)\n",
    "        plt.scatter(x,y,color = col)\n",
    "        report_extreme_ratios(x,y,name)    \n",
    "    plot_two_sensors(plot_mean_error_vs_sigma, 'AIRS variation', 'Prediction error / sigma (mean)', lambda:0)\n",
    "    \n",
    "    plt.figure(); basics()\n",
    "    plt.title('AIRS variation per planet')\n",
    "    plt.xlabel('Sigma prediction')\n",
    "    plt.ylabel('STD error')\n",
    "    n=282\n",
    "    x=np.sqrt([(np.trace(d.spectrum_cov[1:,1:]) - np.sum(d.spectrum_cov[1:,1:]) / n) / n for d in inferred_data])\n",
    "    y=np.sqrt(np.var(error_matrix[:,1:],1))\n",
    "    plt.scatter(x, y, color='red')\n",
    "    plt.axline((0,0), slope=1, color='black')\n",
    "    report_extreme_ratios(x,y,'AIRS variation')    \n",
    "    plt.pause(0.001)\n",
    "    \n",
    "    def plot_mean_error_vs_sigma(slic,col, name):\n",
    "        x = np.mean(true_matrix[:,slic],1)\n",
    "        y = np.sqrt(np.var(error_matrix[:,1:],1)) / np.sqrt([(np.trace(d.spectrum_cov[1:,1:]) - np.sum(d.spectrum_cov[1:,1:]) / n) / n for d in inferred_data])\n",
    "        plt.scatter(x,y,color = col)\n",
    "        report_extreme_ratios(x,y,name)    \n",
    "    plot_two_sensors(plot_mean_error_vs_sigma, 'True value (mean)', 'Prediction error / sigma (AIRS variation)', lambda:0)\n",
    "    \n",
    "    def plot_mean_error_vs_sigma(slic,col, name):\n",
    "        x = np.std(true_matrix[:,1:],1)\n",
    "        y = np.sqrt(np.var(error_matrix[:,1:],1)) / np.sqrt([(np.trace(d.spectrum_cov[1:,1:]) - np.sum(d.spectrum_cov[1:,1:]) / n) / n for d in inferred_data])\n",
    "        plt.scatter(x,y,color = col)\n",
    "        report_extreme_ratios(x,y,name)    \n",
    "    plot_two_sensors(plot_mean_error_vs_sigma, 'AIRS variation', 'Prediction error / sigma (AIRS variation)', lambda:0)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3368a0-8d05-4d07-b9ff-0f24e96c7359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.bias_a, model.bias_b, model.sigma_base_addition, model.sigma_var_scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba89d03f-6d3b-4219-ad85-87e6d4a9bfe9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compare1= list(todo.keys())[0]\n",
    "data1 = kgs.dill_load(fname(compare1))[0]\n",
    "if ignore_bad_planets:\n",
    "    data1 = filter_bad_data(data1)\n",
    "for k,v in todo.items():    \n",
    "    compare2= k\n",
    "    if compare2==compare1:\n",
    "        continue    \n",
    "    data2 = kgs.dill_load(fname(compare2))[0]\n",
    "    if ignore_bad_planets:\n",
    "        data2 = filter_bad_data(data2)\n",
    "        train_data_here = filter_bad_data(train_data)\n",
    "    else:\n",
    "        train_data_here = train_data           \n",
    "    error1 = np.array([d.spectrum - t.spectrum for d,t in zip(data1,train_data_here)])\n",
    "    error2 = np.array([d.spectrum - t.spectrum for d,t in zip(data2,train_data_here)])\n",
    "    def plot_prediction_vs_true(slic, col, name):\n",
    "        x = np.mean(error1[:,slic],1)\n",
    "        y = np.mean(error2[:,slic],1)\n",
    "        plt.scatter(x,y,color = col)\n",
    "\n",
    "    plot_two_sensors(plot_prediction_vs_true, compare1+' (mean)', compare2+' (mean)', lambda:plt.axline((0,0),slope=1,color='black'))\n",
    "\n",
    "    plt.figure(); basics()\n",
    "    plt.title('AIRS variation per planet')\n",
    "    plt.xlabel(compare1)\n",
    "    plt.ylabel(compare2)\n",
    "    x=np.sqrt(np.var(error1[:,1:],1))\n",
    "    y=np.sqrt(np.var(error2[:,1:],1))\n",
    "    plt.scatter(x, y, color='red')\n",
    "    plt.axline((0,0), slope=1, color='black')\n",
    "    plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476f6bc8-683e-4ba1-8660-9b49a80f1e80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "\n",
    "# # Hibernate Windows\n",
    "# subprocess.run(\n",
    "#     [\"/mnt/c/Windows/System32/shutdown.exe\", \"/h\"],  # add \"/f\" to force-close apps\n",
    "#     check=True\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
